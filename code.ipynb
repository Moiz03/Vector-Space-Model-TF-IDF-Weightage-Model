{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bV8aJD9yo7CD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import os\n",
        "from collections import Counter\n",
        "import string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cnuaEhqo7CI"
      },
      "source": [
        "<h3 style = 'color:purple;'>Vector Space Model (TF-IDF Weightage Model)</h3>\n",
        "\n",
        "$$ f(q,d) = sim(q,d) =  \\sum_{i=1}^n x_iy_i $$ \n",
        "q = (x_1,.....,x_n) <br>\n",
        "d = (y_1,.....,y_n) <br>\n",
        "x_i = count of word W_i in query. <br>\n",
        "y_i = TF-IDF of word W_i in doc i.e $$ y_i = C(W_i,doc) * log_2 \\frac {M+1} {k} $$\n",
        "M = number of documents in the collection <br>\n",
        "k = document frequency for every word in corpus\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZVkz_YRo7CH"
      },
      "source": [
        "**M = 5 as it is assumed that the collection has 5 docs only.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "## sample documents to understand code easily\n",
        "documents = {\n",
        "    \"d1\" : \"news about\",\n",
        "    \"d2\" : \"news about organic food campaign\",\n",
        "    \"d3\" : \"news of presidential campaign\",\n",
        "    \"d4\" : \"news of presidential campaign presidential candidate\",\n",
        "    \"d5\" : \"news of organic food campaign campaign campaign campaign\"\n",
        "}\n",
        "\n",
        "\n",
        "### you can use it to work on big file\n",
        "\n",
        "\n",
        "## uploading document from Data_Updated folder\n",
        "\n",
        "# documents = {}\n",
        "# for filename in os.listdir(\"Data-updated\"):\n",
        "#     file = open(\"Data-updated/\"+filename, \"r\",errors = \"ignore\")\n",
        "#     file = file.read()\n",
        "#     documents[filename] = file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# vocabulary \n",
        "\n",
        "vocab = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Write a function named wordList(doc) in such a way that it takes a txt\n",
        "file as input argument and returns a list of words in your document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BC3nCQGAo7CS"
      },
      "outputs": [],
      "source": [
        "## return list of word after separating each word on the basis of space\n",
        "\n",
        "def wordList(doc):\n",
        "    word_list = doc.split(\" \")\n",
        "    return word_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Write a function named removePuncs(wordList) that takes list of\n",
        "words then iterate through this list. During iteration it do some\n",
        "processing on each word. Function should replace punctuation marks\n",
        "as well as \\n. and check either this word in stopword on not? if it is in\n",
        "stopword then we didn't append this into resulting List."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "## remove punctation and all the stop words from the list of words\n",
        "\n",
        "def removePuncs(wordList):\n",
        "    stopword_list = stopwords.words(\"english\")\n",
        "    update_wordList = []\n",
        "    for word in wordList:\n",
        "        trimmed_word = word.translate(str.maketrans('', '', string.punctuation))    #remove punctuation\n",
        "        if (trimmed_word not in stopword_list) and len(trimmed_word)>0:             #remove stopwords and empty words\n",
        "            update_wordList.append(trimmed_word)\n",
        "          \n",
        "    return update_wordList "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Write a function named termFrequencyInDoc(wordList) which\n",
        "should take a list of words asinput argument, and output a dictionary\n",
        "of words such that each word that appears in the document is key in\n",
        "the dictionary and it's value is term frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "#take the word list of document and find the term frequency and return the dictinoary \n",
        "\n",
        "def termFrequencyInDoc(wordsList):\n",
        "    dictionary  = {}\n",
        "    setOfWords = set(wordsList)\n",
        "    for word in setOfWords:\n",
        "        dictionary[word] = wordsList.count(word)\n",
        "    return dictionary  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Write a function named wordDocFre(dicList) that takes list of\n",
        "dictionary as input argument, each dictionary in this list is the word\n",
        "that appears in the given document as keys and the no. of times the\n",
        "word appears as value. This function should construct a dictionary\n",
        "which has all the words that appear in the corpus as keys and no. of\n",
        "docs that contain this word as value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-wKx5ximo7CX"
      },
      "outputs": [],
      "source": [
        "def wordDocFre(dicList):\n",
        "    df_corpus = {}\n",
        "    for word in vocab:\n",
        "        df_corpus[word] = 0\n",
        "\n",
        "    for word in vocab:\n",
        "        count = 0\n",
        "        for dic in dicList.values():\n",
        "            if word in dic:\n",
        "                count += 1\n",
        "        df_corpus[word] = count\n",
        "        \n",
        "    return df_corpus\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Construct a function named inverseDocFre(dicList,base) that takes\n",
        "dictionary returned from wordDocFre functions above and outputs\n",
        "inverse document frequency of each word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "evrsElsio7Cc"
      },
      "outputs": [],
      "source": [
        "\n",
        "def inverseDocFre(dicList,base):\n",
        "    #since we have calculated k (document frequency) for all the words in the corpus, next step is to calculate idf\n",
        "    M = len(documents) #number of documents in the collection\n",
        "    idf_corpus = {} #inverse_document frequency for every word in corpus\n",
        "    for word in vocab:\n",
        "        idf_corpus[word] = (np.log((M+1) / dicList[word])) / np.log(base) #log_2 ((M+1)/k) i.e inverse document frequency\n",
        "    return idf_corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function named tfidf(docList) takes list of documents it calls\n",
        "the function wordList to split the document in list of words and\n",
        "remove stopwords and punctuation marks from them, then calls\n",
        "termFrequencyInDoc() uses its output to create dictionary of\n",
        "vocabulary using the function wordDocFre(), it then should call\n",
        "inverseDocFre() function. It then outputs a list of dictionary, where\n",
        "each document corresponds to the dictionary, its words should be\n",
        "keys values should be tf-idf score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tfidf(docList):        \n",
        "    \n",
        "    tf_dictionary = {}\n",
        "    for key, value in docList.items():\n",
        "        words = wordList(value)\n",
        "        words = removePuncs(words)\n",
        "\n",
        "        for word in words:\n",
        "            if word not in vocab:\n",
        "                vocab.append(word)\n",
        "\n",
        "        dic = termFrequencyInDoc(words)\n",
        "        tf_dictionary[key] = dic\n",
        "    \n",
        "        \n",
        "    idf_corpus = inverseDocFre(wordDocFre(tf_dictionary),2)\n",
        "\n",
        "    tf_idf_docs = {}  # will store tf_idf scores for document words\n",
        "    for doc_id in tf_dictionary.keys():\n",
        "        tf_idf_docs[doc_id] = {}\n",
        "    \n",
        "    for word in vocab:\n",
        "        for doc_id,doc in tf_dictionary.items(): #iterate through key,value pairs where key = doc_id and value = doc content\n",
        "            tf_frequency = 0\n",
        "            if word in doc:\n",
        "                tf_frequency = doc[word]\n",
        "\n",
        "            tf_idf_docs[doc_id][word] = tf_frequency * idf_corpus[word] #C(W_i,doc) * IDF(W_i)\n",
        "    \n",
        "    return tf_idf_docs   \n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksTOOZgeo7Ci"
      },
      "source": [
        "Write a code for VSM, Function header\n",
        "should be like this vectorSpaceModel(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def vectorSpaceModel(query , tf_idf_docs):\n",
        "    query_vocab = removePuncs(wordList(query))\n",
        "    query_wc = {} # a dictionary to store count of a word in the query (i.e x_i according to lecture slides terminology)\n",
        "    for word in query_vocab:\n",
        "        query_wc[word] = query.split().count(word)\n",
        "    \n",
        "    relevance_scores = {} # a dictionary that will store the relevance score for each doc\n",
        "    # doc_id will be the key and relevance score the value for this dictionary\n",
        "    for doc_id in documents.keys():\n",
        "        score = 0 #initialze the score for the doc to 0 at the start\n",
        "        for word in query_vocab:\n",
        "            if word in tf_idf_docs[doc_id]:\n",
        "                score += query_wc[word] * tf_idf_docs[doc_id][word] # count of word in query * term_freq of the word\n",
        "        relevance_scores[doc_id] = score\n",
        "    \n",
        "    return relevance_scores\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Queries on which run the VSM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "queries = [\n",
        "    \"LDA\", \"Topic modelling\", \"Generative models\", \"Semantic relationships between terms\", \"Natural Language Processing\", \"Text Mining\",\n",
        "    \"Translation model\", \"Learning procedures for the lexicon\", \"Semantic evaluations\", \"System results and combination\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Main Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query : LDA \n",
            "Result : [('d1', 0), ('d2', 0), ('d3', 0), ('d4', 0), ('d5', 0)]\n",
            "Query : Topic modelling \n",
            "Result : [('d1', 0), ('d2', 0), ('d3', 0), ('d4', 0), ('d5', 0)]\n",
            "Query : Generative models \n",
            "Result : [('d1', 0), ('d2', 0), ('d3', 0), ('d4', 0), ('d5', 0)]\n",
            "Query : Semantic relationships between terms \n",
            "Result : [('d1', 0), ('d2', 0), ('d3', 0), ('d4', 0), ('d5', 0)]\n",
            "Query : Natural Language Processing \n",
            "Result : [('d1', 0), ('d2', 0), ('d3', 0), ('d4', 0), ('d5', 0)]\n",
            "Query : Text Mining \n",
            "Result : [('d1', 0), ('d2', 0), ('d3', 0), ('d4', 0), ('d5', 0)]\n",
            "Query : Translation model \n",
            "Result : [('d1', 0), ('d2', 0), ('d3', 0), ('d4', 0), ('d5', 0)]\n",
            "Query : Learning procedures for the lexicon \n",
            "Result : [('d1', 0), ('d2', 0), ('d3', 0), ('d4', 0), ('d5', 0)]\n",
            "Query : Semantic evaluations \n",
            "Result : [('d1', 0), ('d2', 0), ('d3', 0), ('d4', 0), ('d5', 0)]\n",
            "Query : System results and combination \n",
            "Result : [('d1', 0), ('d2', 0), ('d3', 0), ('d4', 0), ('d5', 0)]\n"
          ]
        }
      ],
      "source": [
        "tf_idf_docs = (tfidf(documents))\n",
        "for query in queries:\n",
        "    relevance = vectorSpaceModel(query , tf_idf_docs)\n",
        "    relevance_scores = Counter(relevance)\n",
        "    \n",
        "    # Finding 5 highest values\n",
        "    highest = relevance_scores.most_common(5)\n",
        "    print(f\"Query : {query} \\nResult : {highest}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TF_IDF.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "a7c0feeccef1b7abf1cfd7831a3e7c619c84c3a27c5d722b90cbfac046c62a36"
    },
    "kernelspec": {
      "display_name": "Python 3.10.3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
